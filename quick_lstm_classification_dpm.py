# -*- coding: utf-8 -*-
"""Copy of quick_lstm_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tHNs9CHImW8anYKRsSdw4DkYQAZD9O1-
"""

from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import LSTM
from keras.utils import plot_model, to_categorical, normalize
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt

import numpy as np
import random

def make_lines(examples_length, sample_length = 50, offset_minmax = (-0.5, 0.5), slope_minmax = (-0.5, 0.5), noiseAmp = 0.1, label=0):
    #input is [batch_size, x (y, z ...)]
    offsets = np.random.uniform(offset_minmax[0], offset_minmax[1], examples_length)
    slopes  = np.random.uniform(slope_minmax[0],  slope_minmax[1] , examples_length)
    x = np.zeros( [examples_length,sample_length] )
    y = np.full((examples_length), label)
    for i in range(examples_length):
        x[i,:] = slopes[i]*( np.linspace(0.0, 1.0, sample_length) - .5 ) + offsets[i] + noiseAmp * np.random.random(sample_length)
    return x,y

def make_sines(examples_length, sample_length = 50, offset_minmax = (-0.5, 0.5), amplitude_minmax = (-1, 1), omega_minmax = (1, 4), noiseAmp = 0.1, label=1):
    #assume t_final is examples_length/(2*np.pi) so omega = 1 is one complete cycles
    #hardcoding random phase offsets evenly distributed from 0 to 2pi
    t = np.linspace(0, 2.0*np.pi, sample_length)
    offsets       = np.random.uniform(offset_minmax[0],     offset_minmax[1],     examples_length)
    amplitudes    = .5*np.random.uniform(amplitude_minmax[0],  amplitude_minmax[1],  examples_length)
    omegas        = np.random.uniform(omega_minmax[0],      omega_minmax[1],      examples_length)
    phase_offsets = np.linspace(0, 2.0*np.pi, examples_length)
   
    x = np.zeros( [examples_length, sample_length] )
    y = np.full((examples_length), label)
    for i in range(examples_length):
        x[i,:] = amplitudes[i]*np.sin(t*omegas[i] + phase_offsets[i]) + offsets[i] + noiseAmp * np.random.random(sample_length)
    return x,y

"""## Data"""
#%%
#@title Parameters
#@markdown **Data parameters**
seq_length = 100 #@param {type:"slider", min:1, max:100, step:1}

examples = 5000 #@param {type:"slider", min:1, max:100000, step:10}

#@markdown **Model parameters**
lstm_units = 30 #@param {type:"slider", min:4, max:100, step:1}
epochs = 10 #@param {type:"slider", min:1, max:100, step:1}

# generate training/testing values

class_num = 2 # two wave types
x1,y1 = make_lines(examples//2, seq_length, noiseAmp = 0.01)
x2,y2 = make_sines(examples//2, seq_length, noiseAmp = 0.01)
#%%
plt.figure(); 
plt.plot(np.transpose(x1[:100,:]) ,'b')
plt.plot(np.transpose(x2[:100,:]) ,'r')

#%%
# Shuffle together
train_x,train_y = shuffle(np.concatenate([x1,x2]), np.concatenate([y1,y2]))
#%%
# plot a few examples for sanity
plt.plot(train_x[:10,].swapaxes(0,1))

# shape x appropiately
train_x = train_x.reshape(train_x.shape[0],train_x.shape[1], 1)
#%%
# make y binary catagorical 
train_y = to_categorical(train_y, class_num)

# split train and test
train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.2)

print("train_x", train_x.shape)
print("train_y", train_y.shape)
print("test_x", test_x.shape)
print("test_y", test_y.shape)
#%%
"""##Model"""

print('Building model...')

# network structure
model = Sequential()

# try "stacking" more LSTM layers
# note that the first RNN/LSTM in a stack will need to have return_sequence=True -
# this results in the LSTM returning the whole sequence, rather than the output of
# last time step

features = 1
model.add(LSTM(lstm_units, activation='relu', input_shape=(seq_length, features)))
# try sigmoid
model.add(Dense(class_num, activation='softmax'))
# Try restructuring for binary crossentropy
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])
#%%
print(model.summary())

history = model.fit(train_x, train_y, epochs=epochs, verbose=2, validation_split=0.2)
#%%
"""## Eval"""

evl = model.evaluate(test_x, test_y)
print(f"accuracy: {evl[1]}")
print(f"loss: {evl[0]}")

pred = model.predict_classes(test_x)
compare_y = np.array([int(n[1]) for n in test_y])

print("truth:")
print(compare_y[:30])

print("prediction:")
print(pred[:30])

print("incorrect:")
print(compare_y[:30]^pred[:30])
